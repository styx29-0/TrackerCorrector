{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追踪可视化\n",
    "\n",
    "可视化视频中的框的颜色的解释:\n",
    "- 红色: 真值。\n",
    "- 蓝色: 原模型预测。\n",
    "- 灰色: 纠偏过程中tracker的预测结果。\n",
    "- 黄色: 纠偏后的结果, 如果未发生纠偏, 与灰色框相同(会将灰色完全覆盖)。\n",
    "- 橙色: tracker对应的search图像。\n",
    "- 紫色: 纠偏网络对应的search图像。\n",
    "- 黑色: template对应的search图像。\n",
    "- 绿色+: 眼动cx和cy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数量： 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skydiving:   0%|          | 6/1568 [00:00<00:27, 56.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skydiving: 100%|██████████| 1568/1568 [00:27<00:00, 56.22it/s]\n",
      "bowling_1: 100%|██████████| 2417/2417 [00:28<00:00, 84.53it/s]\n",
      "pingpong_2: 100%|██████████| 10209/10209 [01:26<00:00, 118.17it/s]\n"
     ]
    }
   ],
   "source": [
    "runid = '74'\n",
    "subject_name = 'liweilong'\n",
    "fps = 240 # TODO 30 240\n",
    "# data\n",
    "# with open(f'/data/xgxy/BeiJing/code/VideoX/SeqTrack/workspace/plot/lasot/eval_data_run{runid.zfill(2)}.pkl', 'rb') as f:\n",
    "#     eval_data_exp = pickle.load(f)\n",
    "# sample_list = eval_data_exp['sequences']\n",
    "# 0%-10%\n",
    "sequence_list = ['pingpong_2']\n",
    "# 0%-20%\n",
    "sequence_list = ['Skydiving', 'bowling_1', 'pingpong_2']\n",
    "# 单独跑一些样本\n",
    "# sequence_list = ['airboard_1', 'basketball_1', 'car', 'dog', 'shuffleboard_1', 'soccer_ball']\n",
    "sample_list = sequence_list\n",
    "print('样本数量：', len(sample_list))\n",
    "\n",
    "output_dir = os.path.join('/data/guohua/BeiJing/code/VideoX.back/visual', 'nfs', subject_name, runid)\n",
    "ori_pred_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_999/nfs' \n",
    "seqtrack_pred_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/nfs' # 修改成纠偏网络的输入\n",
    "pred_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/nfs'\n",
    "search_bbox_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/nfs'\n",
    "search_bbox_eye_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/nfs'\n",
    "template_bbox_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/nfs'\n",
    "eye_dir = f'/data/guohua/BeiJing/data/NFS-eye-sy/{subject_name}'\n",
    "data_dir = '/data/guohua/BeiJing/data/Nfs' # /data/guohua/BeiJing/data/lasot\n",
    "\n",
    "# 字体参数\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "line_type = 2\n",
    "\n",
    "video_dir = os.path.join(output_dir)\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "for s in sample_list:\n",
    "    # if s in sequence_list: continue\n",
    "    s_dir = s # lasot .split('-')[0]\n",
    "    sample_dir = os.path.join(data_dir, s_dir, '240') # 240 \n",
    "    image_list = sorted(glob.glob(f\"{os.path.join(sample_dir, s)}/*.jpg\"))\n",
    "    # 真值\n",
    "    gt_file_path = os.path.join(sample_dir, 'groundtruth.txt')\n",
    "    gt_list = np.loadtxt(gt_file_path, delimiter=',', dtype=np.int32)\n",
    "    # 原模型预测值\n",
    "    ori_pred_file_path = os.path.join(ori_pred_dir, f'nfs_{s}.txt')\n",
    "    ori_pred_list = np.loadtxt(ori_pred_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # 纠偏网络的输入\n",
    "    seqtrack_pred_file_path = os.path.join(seqtrack_pred_dir, f'nfs_{s}_seqtrack.txt')\n",
    "    seqtrack_pred_list = np.loadtxt(seqtrack_pred_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # 预测值\n",
    "    pred_file_path = os.path.join(pred_dir, f'nfs_{s}.txt')\n",
    "    pred_list = np.loadtxt(pred_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # search_bbox\n",
    "    search_bbox_file_path = os.path.join(search_bbox_dir, f'nfs_{s}_search.txt')\n",
    "    search_bbox_list = np.loadtxt(search_bbox_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # search_bbox_eye\n",
    "    search_bbox_eye_file_path = os.path.join(search_bbox_eye_dir, f'nfs_{s}_search_eye.txt')\n",
    "    search_bbox_eye_list = np.loadtxt(search_bbox_eye_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # template_bbox\n",
    "    template_bbox_file_path = os.path.join(template_bbox_dir, f'nfs_{s}_template.txt')\n",
    "    template_bbox_list = np.loadtxt(template_bbox_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # 眼动数据\n",
    "    eye_file_path = os.path.join(eye_dir, s_dir, f'{s}.txt')\n",
    "    eye_list = np.loadtxt(eye_file_path, delimiter=',', dtype=np.int32)\n",
    "\n",
    "    # 获取图片尺寸\n",
    "    first_image = cv2.imread(image_list[0])\n",
    "    height, width, layers = first_image.shape\n",
    "    # 初始化视频写入对象\n",
    "    video_path = os.path.join(video_dir, f'{s}.mp4')\n",
    "    # if os.path.exists(video_path):\n",
    "    #     continue\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(video_path, fourcc, fps=fps, frameSize=(width, height))\n",
    "    \n",
    "    gtw, gth = gt_list[0][2], gt_list[0][3]\n",
    "    # 遍历每张图片并绘制真值和预测框\n",
    "    for j, image_path in enumerate(tqdm(image_list, desc=f'{s}')):\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # 获取真值, 预测结果和眼动结果\n",
    "        gt = gt_list[j]\n",
    "        ori_pred = ori_pred_list[j]\n",
    "        seqtrack_pred = seqtrack_pred_list[j]\n",
    "        pred = pred_list[j]\n",
    "        search_bbox = search_bbox_list[j]\n",
    "        search_bbox_eye = search_bbox_eye_list[j]\n",
    "        eye = eye_list[j]\n",
    "        template_bbox = template_bbox_list[j]\n",
    "        \n",
    "        if gt is not None:\n",
    "            # 计算真值框的左上角和右下角坐标\n",
    "            gt_x, gt_y, gt_w, gt_h = int(gt[0]), int(gt[1]), int(gt[2]), int(gt[3])\n",
    "            gt_top_left = (gt_x, gt_y)\n",
    "            gt_bottom_right = (gt_x + gt_w, gt_y + gt_h)\n",
    "            # 画真值框\n",
    "            cv2.rectangle(img, gt_top_left, gt_bottom_right, (0, 0, 255), 2)  # 红色框\n",
    "            # text_org = (gt_top_left[0], gt_top_left[1] + gt[3] - 12)\n",
    "            # cv2.putText(img, f'Ground-truth', text_org, font, font_scale, (0, 0, 255), line_type)\n",
    "            \n",
    "        if ori_pred is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            ori_pred_x, ori_pred_y, ori_pred_w, ori_pred_h = int(ori_pred[0]), int(ori_pred[1]), int(ori_pred[2]), int(ori_pred[3])\n",
    "            ori_pred_top_left = (ori_pred_x, ori_pred_y)\n",
    "            ori_pred_bottom_right = (ori_pred_x + ori_pred_w, ori_pred_y + ori_pred_h)\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, ori_pred_top_left, ori_pred_bottom_right, (255, 0, 0), 2)  # 蓝色框\n",
    "            # 标记预测值\n",
    "            # text_org = (ori_pred_top_left[0] - 15, ori_pred_top_left[1] - 10)\n",
    "            # cv2.putText(img, f'{frame_auc_no_ext[s][j].item():.2f}', text_org, font, font_scale, (255, 0, 0), line_type)\n",
    "            # cv2.putText(img, f'Original prediction', text_org, font, font_scale, (255, 0, 0), line_type)\n",
    "        \n",
    "        if seqtrack_pred is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            seqtrack_pred_x, seqtrack_pred_y, seqtrack_pred_w, seqtrack_pred_h = int(seqtrack_pred[0]), int(seqtrack_pred[1]), int(seqtrack_pred[2]), int(seqtrack_pred[3])\n",
    "            seqtrack_pred_top_left = (seqtrack_pred_x, seqtrack_pred_y)\n",
    "            seqtrack_pred_bottom_right = (seqtrack_pred_x + seqtrack_pred_w, seqtrack_pred_y + seqtrack_pred_h)\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, seqtrack_pred_top_left, seqtrack_pred_bottom_right, (181, 181, 181), 2) # grey71\n",
    "\n",
    "        if pred is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            pred_x, pred_y, pred_w, pred_h = int(pred[0]), int(pred[1]), int(pred[2]), int(pred[3])\n",
    "            pred_top_left = (pred_x, pred_y)\n",
    "            pred_bottom_right = (pred_x + pred_w, pred_y + pred_h)\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, pred_top_left, pred_bottom_right, (0, 255, 255), 2)  # 黄\n",
    "            # 标记预测值\n",
    "            # text_org = (pred_top_left[0] - 10, pred_top_left[1] - 12)\n",
    "            # cv2.putText(img, f'{frame_auc_no_ext[s][j].item():.2f}', text_org, font, font_scale, (255, 0, 0), line_type)\n",
    "            # cv2.putText(img, f'Improved prediction', text_org, font, font_scale, (0, 255, 255), line_type)\n",
    "\n",
    "        if search_bbox is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            search_bbox_x0, search_bbox_y0, search_bbox_x1, search_bbox_y1 = int(search_bbox[0]), int(search_bbox[1]), int(search_bbox[2]), int(search_bbox[3])\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, [search_bbox_x0, search_bbox_y0], [search_bbox_x1, search_bbox_y1], (0, 165, 255), 2)  # Yellow1\n",
    "        \n",
    "        if search_bbox_eye is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            search_bbox_eye_x0, search_bbox_eye_y0, search_bbox_eye_x1, search_bbox_eye_y1 = int(search_bbox_eye[0]), int(search_bbox_eye[1]), int(search_bbox_eye[2]), int(search_bbox_eye[3])\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, [search_bbox_eye_x0, search_bbox_eye_y0], [search_bbox_eye_x1, search_bbox_eye_y1], (255, 0, 255), 2)  # 紫色\n",
    "        \n",
    "        if template_bbox is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            template_bbox_x0, template_bbox_y0, template_bbox_x1, template_bbox_y1 = int(template_bbox[0]), int(template_bbox[1]), int(template_bbox[2]), int(template_bbox[3])\n",
    "            if j == 0: \n",
    "                template_top_left = (template_bbox_x0, template_bbox_y0)\n",
    "                template_bottom_right = (template_bbox_x0 + template_bbox_x1, template_bbox_y0 + template_bbox_y1)\n",
    "                # 画预测框\n",
    "                cv2.rectangle(img, template_top_left, template_bottom_right, (0, 0, 0), 2)  # black\n",
    "            else:\n",
    "                cv2.rectangle(img, [template_bbox_x0, template_bbox_y0], [template_bbox_x1, template_bbox_y1], (0, 0, 0), 2) # black\n",
    "\n",
    "        if eye is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            # eye_x, eye_y, eye_w, eye_h = int(eye[0]), int(eye[1]), int(eye[2]), int(eye[3])\n",
    "            # eye_top_left = (eye_x - eye_w//2, eye_y - eye_h//2)\n",
    "            # eye_bottom_right = (eye_x + eye_w//2, eye_y + eye_h//2)\n",
    "            # 画预测框\n",
    "            # cv2.rectangle(img, eye_top_left, eye_bottom_right, (0, 255, 0), 2)  # 绿色框\n",
    "            # 标记预测值\n",
    "            # text_org = (eye_top_left[0], eye_top_left[1] - 10)\n",
    "            # cv2.putText(img, f'{eye_frame_auc_no_ext[s][j].item():.2f}', text_org, font, font_scale, (0, 255, 0), line_type)\n",
    "            eye_x, eye_y= int(eye[0]), int(eye[1])\n",
    "            cv2.drawMarker(img, (eye_x, eye_y), (0, 255, 0), markerType=cv2.MARKER_CROSS, markerSize=20, thickness=2)  # 绿色\"+\"\n",
    "\n",
    "        # 写入视频\n",
    "        video.write(img)\n",
    "\n",
    "    # 释放视频写入对象\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数量： 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bike2: 100%|██████████| 553/553 [00:05<00:00, 97.23it/s]\n",
      "bird1_2: 100%|██████████| 703/703 [00:08<00:00, 78.66it/s] \n",
      "bird1_3: 100%|██████████| 865/865 [00:11<00:00, 73.14it/s]\n",
      "uav1_3: 100%|██████████| 997/997 [00:05<00:00, 171.96it/s]\n",
      "uav4: 100%|██████████| 157/157 [00:00<00:00, 189.00it/s]\n",
      "uav7: 100%|██████████| 373/373 [00:02<00:00, 177.60it/s]\n",
      "uav8: 100%|██████████| 301/301 [00:02<00:00, 121.96it/s]\n"
     ]
    }
   ],
   "source": [
    "runid = '74'\n",
    "subject_name = 'liweilong'\n",
    "fps = 30 # TODO 30 240\n",
    "# data\n",
    "# with open(f'/data/xgxy/BeiJing/code/VideoX/SeqTrack/workspace/plot/lasot/eval_data_run{runid.zfill(2)}.pkl', 'rb') as f:\n",
    "#     eval_data_exp = pickle.load(f)\n",
    "# sample_list = eval_data_exp['sequences']\n",
    "# 0%-10%\n",
    "sequence_list = ['uav4', 'uav8']\n",
    "# 0%-20%\n",
    "sequence_list = ['bike2', 'bird1_2', 'bird1_3', 'uav1_3', 'uav4', 'uav7', 'uav8']\n",
    "# 单独跑一些样本\n",
    "# sequence_list = ['bike1', 'bird1_1', 'car15', 'person10', 'uav5', 'wakeboard10', 'truck1', 'building5', 'boat5'] # 'bike1', 'car15', 'person10', 'uav5', 'wakeboard10', 'truck1', 'building5', 'boat5'\n",
    "sample_list = sequence_list\n",
    "print('样本数量：', len(sample_list))\n",
    "\n",
    "output_dir = os.path.join('/data/guohua/BeiJing/code/VideoX.back/visual', 'uav', subject_name, runid)\n",
    "ori_pred_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_999/uav' \n",
    "seqtrack_pred_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/uav' # 修改成纠偏网络的输入\n",
    "pred_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/uav'\n",
    "search_bbox_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/uav'\n",
    "search_bbox_eye_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/uav'\n",
    "template_bbox_dir = f'/data/guohua/BeiJing/code/VideoX.back/SeqTrack/test/tracking_results/seqtrack/seqtrack_b256_{runid.zfill(3)}/uav'\n",
    "eye_dir = f'/data/guohua/BeiJing/data/UAV-eye-sy/{subject_name}'\n",
    "new_eye_dir = '/data/guohua/BeiJing/data/lasot-eye-sy'\n",
    "data_dir = '/data/guohua/BeiJing/data/UAV123/UAV_Lasot_struc' # /data/guohua/BeiJing/data/lasot\n",
    "\n",
    "# 字体参数\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "line_type = 2\n",
    "\n",
    "video_dir = os.path.join(output_dir)\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "for s in sample_list:\n",
    "    # if s in sequence_list: continue\n",
    "    s_dir = s.split('_')[0]\n",
    "    sample_dir = os.path.join(data_dir, s_dir, s) # lasot \n",
    "    image_list = sorted(glob.glob(f\"{os.path.join(sample_dir, 'img')}/*.jpg\"))\n",
    "    # 真值\n",
    "    gt_file_path = os.path.join(sample_dir, 'groundtruth.txt')\n",
    "    gt_list = np.loadtxt(gt_file_path, delimiter=',', dtype=np.int32)\n",
    "    # 原模型预测值\n",
    "    ori_pred_file_path = os.path.join(ori_pred_dir, f'uav_{s}.txt')\n",
    "    ori_pred_list = np.loadtxt(ori_pred_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # 纠偏网络的输入\n",
    "    seqtrack_pred_file_path = os.path.join(seqtrack_pred_dir, f'uav_{s}_seqtrack.txt')\n",
    "    seqtrack_pred_list = np.loadtxt(seqtrack_pred_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # 预测值\n",
    "    pred_file_path = os.path.join(pred_dir, f'uav_{s}.txt')\n",
    "    pred_list = np.loadtxt(pred_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # search_bbox\n",
    "    search_bbox_file_path = os.path.join(search_bbox_dir, f'uav_{s}_search.txt')\n",
    "    search_bbox_list = np.loadtxt(search_bbox_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # search_bbox_eye\n",
    "    search_bbox_eye_file_path = os.path.join(search_bbox_eye_dir, f'uav_{s}_search_eye.txt')\n",
    "    search_bbox_eye_list = np.loadtxt(search_bbox_eye_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # template_bbox\n",
    "    template_bbox_file_path = os.path.join(template_bbox_dir, f'uav_{s}_template.txt')\n",
    "    template_bbox_list = np.loadtxt(template_bbox_file_path, delimiter='\\t', dtype=np.int32)\n",
    "    # 眼动数据\n",
    "    eye_file_path = os.path.join(eye_dir, s, f'{s}.txt')\n",
    "    eye_list = np.loadtxt(eye_file_path, delimiter=',', dtype=np.int32)\n",
    "\n",
    "    # 获取图片尺寸\n",
    "    first_image = cv2.imread(image_list[0])\n",
    "    height, width, layers = first_image.shape\n",
    "    # 初始化视频写入对象\n",
    "    video_path = os.path.join(video_dir, f'{s}.mp4')\n",
    "    # if os.path.exists(video_path):\n",
    "    #     continue\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(video_path, fourcc, fps=fps, frameSize=(width, height))\n",
    "    \n",
    "    gtw, gth = gt_list[0][2], gt_list[0][3]\n",
    "    # 遍历每张图片并绘制真值和预测框\n",
    "    for j, image_path in enumerate(tqdm(image_list, desc=f'{s}')):\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # 获取真值, 预测结果和眼动结果\n",
    "        gt = gt_list[j]\n",
    "        ori_pred = ori_pred_list[j]\n",
    "        seqtrack_pred = seqtrack_pred_list[j]\n",
    "        pred = pred_list[j]\n",
    "        search_bbox = search_bbox_list[j]\n",
    "        search_bbox_eye = search_bbox_eye_list[j]\n",
    "        eye = eye_list[j]\n",
    "        template_bbox = template_bbox_list[j]\n",
    "        \n",
    "        if gt is not None:\n",
    "            # 计算真值框的左上角和右下角坐标\n",
    "            gt_x, gt_y, gt_w, gt_h = int(gt[0]), int(gt[1]), int(gt[2]), int(gt[3])\n",
    "            gt_top_left = (gt_x, gt_y)\n",
    "            gt_bottom_right = (gt_x + gt_w, gt_y + gt_h)\n",
    "            # 画真值框\n",
    "            cv2.rectangle(img, gt_top_left, gt_bottom_right, (0, 0, 255), 2)  # 红色框\n",
    "            # text_org = (gt_top_left[0], gt_top_left[1] + gt[3] - 12)\n",
    "            # cv2.putText(img, f'Ground-truth', text_org, font, font_scale, (0, 0, 255), line_type)\n",
    "            \n",
    "        if ori_pred is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            ori_pred_x, ori_pred_y, ori_pred_w, ori_pred_h = int(ori_pred[0]), int(ori_pred[1]), int(ori_pred[2]), int(ori_pred[3])\n",
    "            ori_pred_top_left = (ori_pred_x, ori_pred_y)\n",
    "            ori_pred_bottom_right = (ori_pred_x + ori_pred_w, ori_pred_y + ori_pred_h)\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, ori_pred_top_left, ori_pred_bottom_right, (255, 0, 0), 2)  # 蓝色框\n",
    "            # 标记预测值\n",
    "            # text_org = (ori_pred_top_left[0] - 15, ori_pred_top_left[1] - 10)\n",
    "            # cv2.putText(img, f'{frame_auc_no_ext[s][j].item():.2f}', text_org, font, font_scale, (255, 0, 0), line_type)\n",
    "            # cv2.putText(img, f'Original prediction', text_org, font, font_scale, (255, 0, 0), line_type)\n",
    "        \n",
    "        if seqtrack_pred is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            seqtrack_pred_x, seqtrack_pred_y, seqtrack_pred_w, seqtrack_pred_h = int(seqtrack_pred[0]), int(seqtrack_pred[1]), int(seqtrack_pred[2]), int(seqtrack_pred[3])\n",
    "            seqtrack_pred_top_left = (seqtrack_pred_x, seqtrack_pred_y)\n",
    "            seqtrack_pred_bottom_right = (seqtrack_pred_x + seqtrack_pred_w, seqtrack_pred_y + seqtrack_pred_h)\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, seqtrack_pred_top_left, seqtrack_pred_bottom_right, (181, 181, 181), 2) # grey71\n",
    "\n",
    "        if pred is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            pred_x, pred_y, pred_w, pred_h = int(pred[0]), int(pred[1]), int(pred[2]), int(pred[3])\n",
    "            pred_top_left = (pred_x, pred_y)\n",
    "            pred_bottom_right = (pred_x + pred_w, pred_y + pred_h)\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, pred_top_left, pred_bottom_right, (0, 255, 255), 2)  # 黄\n",
    "            # 标记预测值\n",
    "            # text_org = (pred_top_left[0] - 10, pred_top_left[1] - 12)\n",
    "            # cv2.putText(img, f'{frame_auc_no_ext[s][j].item():.2f}', text_org, font, font_scale, (255, 0, 0), line_type)\n",
    "            # cv2.putText(img, f'Improved prediction', text_org, font, font_scale, (0, 255, 255), line_type)\n",
    "\n",
    "        if search_bbox is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            search_bbox_x0, search_bbox_y0, search_bbox_x1, search_bbox_y1 = int(search_bbox[0]), int(search_bbox[1]), int(search_bbox[2]), int(search_bbox[3])\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, [search_bbox_x0, search_bbox_y0], [search_bbox_x1, search_bbox_y1], (0, 165, 255), 2)  # Yellow1\n",
    "        \n",
    "        if search_bbox_eye is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            search_bbox_eye_x0, search_bbox_eye_y0, search_bbox_eye_x1, search_bbox_eye_y1 = int(search_bbox_eye[0]), int(search_bbox_eye[1]), int(search_bbox_eye[2]), int(search_bbox_eye[3])\n",
    "            # 画预测框\n",
    "            cv2.rectangle(img, [search_bbox_eye_x0, search_bbox_eye_y0], [search_bbox_eye_x1, search_bbox_eye_y1], (255, 0, 255), 2)  # 紫色\n",
    "        \n",
    "        if template_bbox is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            template_bbox_x0, template_bbox_y0, template_bbox_x1, template_bbox_y1 = int(template_bbox[0]), int(template_bbox[1]), int(template_bbox[2]), int(template_bbox[3])\n",
    "            if j == 0: \n",
    "                template_top_left = (template_bbox_x0, template_bbox_y0)\n",
    "                template_bottom_right = (template_bbox_x0 + template_bbox_x1, template_bbox_y0 + template_bbox_y1)\n",
    "                # 画预测框\n",
    "                cv2.rectangle(img, template_top_left, template_bottom_right, (0, 0, 0), 2)  # black\n",
    "            else:\n",
    "                cv2.rectangle(img, [template_bbox_x0, template_bbox_y0], [template_bbox_x1, template_bbox_y1], (0, 0, 0), 2) # black\n",
    "\n",
    "        if eye is not None:\n",
    "            # 计算预测框的左上角和右下角坐标\n",
    "            # eye_x, eye_y, eye_w, eye_h = int(eye[0]), int(eye[1]), int(eye[2]), int(eye[3])\n",
    "            # eye_top_left = (eye_x - eye_w//2, eye_y - eye_h//2)\n",
    "            # eye_bottom_right = (eye_x + eye_w//2, eye_y + eye_h//2)\n",
    "            # 画预测框\n",
    "            # cv2.rectangle(img, eye_top_left, eye_bottom_right, (0, 255, 0), 2)  # 绿色框\n",
    "            # 标记预测值\n",
    "            # text_org = (eye_top_left[0], eye_top_left[1] - 10)\n",
    "            # cv2.putText(img, f'{eye_frame_auc_no_ext[s][j].item():.2f}', text_org, font, font_scale, (0, 255, 0), line_type)\n",
    "            eye_x, eye_y= int(eye[0]), int(eye[1])\n",
    "            cv2.drawMarker(img, (eye_x, eye_y), (0, 255, 0), markerType=cv2.MARKER_CROSS, markerSize=20, thickness=2)  # 绿色\"+\"\n",
    "\n",
    "        # 写入视频\n",
    "        video.write(img)\n",
    "\n",
    "    # 释放视频写入对象\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seqtrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
